{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeBlhlPU7NCQ"
      },
      "source": [
        "#Importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m_qb-I_8ybd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "import torch\n",
        "from skimage import io\n",
        "import random\n",
        "import torchvision.transforms as T\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnDeauxn9j6R"
      },
      "source": [
        "#Conexao com o Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocswAU9B_HIg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7eAF-k-RXHP"
      },
      "outputs": [],
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUE_nf3n_d50"
      },
      "outputs": [],
      "source": [
        "pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eDxDTom_nGw"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z2Qx5vY_x--"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi3U6SLy_4rH"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zffW7jKNALZr"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!kaggle datasets download paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTmRp8r8A13i"
      },
      "outputs": [],
      "source": [
        "!unzip chest-xray-pneumonia.zip -d XrayPneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrtD6bf0QmxE"
      },
      "source": [
        "#Transformando os dados em csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gY5mVUSKt6f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def criar_csv(diretorio_raiz, pasta):\n",
        "    caminho_pasta = os.path.join(diretorio_raiz, pasta)\n",
        "    dados = []\n",
        "\n",
        "    for classe in os.listdir(caminho_pasta):\n",
        "        caminho_classe = os.path.join(caminho_pasta, classe)\n",
        "        if os.path.isdir(caminho_classe):  # Verifica se é um diretório\n",
        "            for nome_arquivo in os.listdir(caminho_classe):\n",
        "                if nome_arquivo != '.DS_Store':  # Ignora o arquivo .DS_Store\n",
        "                    dados.append((nome_arquivo, classe))\n",
        "\n",
        "    nome_arquivo_csv = f'dados_{pasta}.csv'\n",
        "\n",
        "    with open(nome_arquivo_csv, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['nome_da_imagem', 'Classe'])\n",
        "        writer.writerows(dados)\n",
        "\n",
        "    print(f'Arquivo CSV \"{nome_arquivo_csv}\" criado com sucesso!')\n",
        "\n",
        "diretorio_raiz = '/content/XrayPneumonia/chest_xray/chest_xray'\n",
        "pastas = ['train', 'test','val']\n",
        "\n",
        "for pasta in pastas:\n",
        "    criar_csv(diretorio_raiz, pasta)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btFCm6fvT7NV"
      },
      "source": [
        "#Transformando dados em dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oficf3kES-os"
      },
      "outputs": [],
      "source": [
        "Train_data = pd.read_csv('/content/dados_train.csv')\n",
        "Test_data = pd.read_csv('/content/dados_test.csv')\n",
        "Val_data = pd.read_csv('/content/dados_val.csv')\n",
        "\n",
        "data = [Train_data,Test_data,Val_data]\n",
        "\n",
        "issue = {'NORMAL':0, 'PNEUMONIA':1}\n",
        "\n",
        "#substituindo para valor\n",
        "for classes in data:\n",
        "  classes['Classe'] = classes['Classe'].map(issue)\n",
        "\n",
        "Train_data['nome_da_imagem']\n",
        "\n",
        "\n",
        "#Testando a imagem\n",
        "resultado = Train_data[Train_data['nome_da_imagem'] == 'person368_virus_748.jpeg']\n",
        "\n",
        "print(resultado)\n",
        "\n",
        "img = cv2.imread('/content/XrayPneumonia/chest_xray/chest_xray/train/PNEUMONIA/person1799_bacteria_4647.jpeg')\n",
        "plt.imshow(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCaVeLnNUA10"
      },
      "source": [
        "#Configurando Dataloader para o pythorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENgVnTu97NpP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class XrayPneumonia(Dataset):\n",
        "    def __init__(self, annotations_file_Dataframe, img_dirs, transform=None, target_transform=None):\n",
        "        self.img_labels = annotations_file_Dataframe\n",
        "        self.img_dirs = img_dirs  # Inicialmente, temos apenas um diretório\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        for img_dir in self.img_dirs:\n",
        "            img_path = os.path.join(img_dir, self.img_labels.iloc[idx, 0])\n",
        "            if os.path.exists(img_path):\n",
        "                image = Image.open(img_path).convert(\"RGB\")  # Forçar a conversão para RGB\n",
        "                label = self.img_labels.iloc[idx, 1]\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                if self.target_transform:\n",
        "                    label = self.target_transform(label)\n",
        "                return image, label\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT54DTAtge5z"
      },
      "source": [
        "#Criando os dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkVSOMRn7mRD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Definir o tamanho fixo para as imagens\n",
        "fixed_size = (256, 256)  # Por exemplo, 224x224 pixels\n",
        "\n",
        "# Definir transformações para redimensionar as imagens\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(fixed_size),\n",
        "    transforms.ToTensor()  # Converte a imagem para tensor\n",
        "])\n",
        "\n",
        "# Aplicar transformações aos conjuntos de dados\n",
        "train_data = XrayPneumonia(Train_data, ['/content/XrayPneumonia/chest_xray/chest_xray/train/NORMAL','/content/XrayPneumonia/chest_xray/chest_xray/train/PNEUMONIA'], transform=transform)\n",
        "test_data = XrayPneumonia(Test_data,  ['/content/XrayPneumonia/chest_xray/chest_xray/test/NORMAL','/content/XrayPneumonia/chest_xray/chest_xray/test/PNEUMONIA'], transform=transform)\n",
        "val_data = XrayPneumonia(Val_data,  ['/content/XrayPneumonia/chest_xray/chest_xray/val/NORMAL','/content/XrayPneumonia/chest_xray/chest_xray/val/PNEUMONIA'], transform=transform)\n",
        "\n",
        "\n",
        "# Criar os DataLoader com os conjuntos de dados transformados\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2),\n",
        "    'test': DataLoader(test_data, batch_size=4, shuffle=True, num_workers=2)\n",
        "}\n",
        "\n",
        "\n",
        "# Tamanhos dos conjuntos de dados\n",
        "dataset_sizes = {\n",
        "    'train': len(train_data),\n",
        "    'test': len(test_data)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNcIvgH95ZDB"
      },
      "source": [
        "#Congelando as camadas para transferlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plmE3eKJ-0X3"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final classification layer\n",
        "for name, param in model.named_parameters():\n",
        "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
        "\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM8Ocae35pPf"
      },
      "source": [
        "#Treinando a Rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE8zGn_3_kFh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in ['train', 'test']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REBRsvgbwrME"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqjvxwr7OoJ4"
      },
      "source": [
        "#Testing the model with an unsee image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9DKCKooPoOg"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'IdentifyPneumonia.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUDxdEoCOXii"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load the saved model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1000)  # Adjust to match the original model's output units\n",
        "model.load_state_dict(torch.load('IdentifyPneumonia.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Create a new model with the correct final layer\n",
        "new_model = models.resnet18(pretrained=True)\n",
        "new_model.fc = nn.Linear(new_model.fc.in_features, 2)  # Adjust to match the desired output units\n",
        "\n",
        "# Copy the weights and biases from the loaded model to the new model\n",
        "new_model.fc.weight.data = model.fc.weight.data[0:2]  # Copy only the first 2 output units\n",
        "new_model.fc.bias.data = model.fc.bias.data[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVG0X-pPOhz_"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the unseen image\n",
        "image_path = '/content/XrayPneumonia/chest_xray/val/PNEUMONIA/person1947_bacteria_4876.jpeg'  # Replace with the path to your image\n",
        "image = Image.open(image_path).convert('L')\n",
        "image = image.convert('RGB')\n",
        "fixed_size = (256, 256)  # Por exemplo, 224x224 pixels\n",
        "\n",
        "# Definir transformações para redimensionar as imagens\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(fixed_size),\n",
        "    transforms.ToTensor()  # Converte a imagem para tensor\n",
        "])\n",
        "\n",
        "input_tensor = transform(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAIDX6GYOkN4"
      },
      "outputs": [],
      "source": [
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "\n",
        "# Get the predicted class\n",
        "_, predicted_class = output.max(1)\n",
        "\n",
        "# Map the predicted class to the class name\n",
        "class_names = [0, 1]  # Make sure these class names match your training data\n",
        "predicted_class_name = class_names[predicted_class.item()]\n",
        "\n",
        "map = {\n",
        "    0: 'NORMAL',\n",
        "    1: 'PNEUMONIA'\n",
        "}\n",
        "\n",
        "print(f'The predicted class is: {map[predicted_class_name]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT05N1TeOl4X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Display the image with the predicted class name\n",
        "image = np.array(image)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.text(10, 10, f'Predicted: {map[predicted_class_name]}', fontsize=12, color='white', backgroundcolor='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssT5PjID1KH6"
      },
      "source": [
        "#Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itJmEfUQ7FfN"
      },
      "source": [
        "Funcao que recebe imagem e o modelo, e retorna a previsao\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vptW4RauH1W"
      },
      "outputs": [],
      "source": [
        "\n",
        "def passa_pela_rede(image_path,model):\n",
        "  image = Image.open(image_path).convert('L')\n",
        "  image = image.convert('RGB')\n",
        "  fixed_size = (256, 256)  # Por exemplo, 224x224 pixels\n",
        "\n",
        "  # Definir transformações para redimensionar as imagens\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(fixed_size),\n",
        "      transforms.ToTensor()  # Converte a imagem para tensor\n",
        "  ])\n",
        "\n",
        "  input_tensor = transform(image)\n",
        "  input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "    # Perform inference\n",
        "  with torch.no_grad():\n",
        "      output = model(input_batch)\n",
        "\n",
        "  # Get the predicted class\n",
        "  _, predicted_class = output.max(1)\n",
        "\n",
        "\n",
        "  # Map the predicted class to the class name\n",
        "  class_names = [0, 1]  # Make sure these class names match your training data\n",
        "  predicted_class_name = class_names[predicted_class.item()]\n",
        "\n",
        "  map = {\n",
        "      0: 'NORMAL',\n",
        "      1: 'PNEUMONIA'\n",
        "  }\n",
        "\n",
        "  return map[predicted_class_name]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5T0SjN27TrQ"
      },
      "source": [
        "Carregando o modelo pré treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igctGAXai73P"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1000)  # Adjust to match the original model's output units\n",
        "model.load_state_dict(torch.load('IdentifyPneumonia.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Create a new model with the correct final layer\n",
        "new_model = models.resnet18(pretrained=True)\n",
        "new_model.fc = nn.Linear(new_model.fc.in_features, 2)  # Adjust to match the desired output units\n",
        "\n",
        "# Copy the weights and biases from the loaded model to the new model\n",
        "new_model.fc.weight.data = model.fc.weight.data[0:2]  # Copy only the first 2 output units\n",
        "new_model.fc.bias.data = model.fc.bias.data[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txCyB9zg69ob"
      },
      "source": [
        "Criando as listas de previsoes e a verdadeira"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6rcK5B0uW1N"
      },
      "outputs": [],
      "source": [
        "img_dirs = ['/content/XrayPneumonia/chest_xray/chest_xray/val/NORMAL','/content/XrayPneumonia/chest_xray/chest_xray/val/PNEUMONIA']\n",
        "\n",
        "\n",
        "predict_list = [] #lista das previsoes\n",
        "true_list = [] #lista das verdadeiras\n",
        "\n",
        "for img_dir in img_dirs: #le cada diretorio\n",
        "  for idx in range(len(Val_data)):\n",
        "    img_path = os.path.join(img_dir, Val_data.iloc[idx, 0]) #cria o image_path\n",
        "\n",
        "    if os.path.exists(img_path): #verifica se o img path existe\n",
        "\n",
        "      true_list.append(Val_data.iloc[idx, 1]) # adicona o a classe verdadeira na true list\n",
        "      predict = passa_pela_rede(img_path, model) #faz a previsao utilizando o modelo\n",
        "      predict_list.append(predict) #adciona na lista de predicts\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "lzXQtkdV1UOJ",
        "outputId": "1a034b48-4d32-43d4-c80f-4e72f7957ef8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "classes = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(true_list, predict_list)\n",
        "df_cm = pd.DataFrame(cf_matrix, index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY8Qyv9n4pLK",
        "outputId": "3f7dc8d2-ebf0-49b9-be6b-f07bb5ac9e0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8125"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy_score(true_list, predict_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrWh3W965RHw",
        "outputId": "4bda1a8c-342c-4f0a-fc2a-3e18b6b6fdd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      NORMAL       1.00      0.62      0.77         8\n",
            "   PNEUMONIA       0.73      1.00      0.84         8\n",
            "\n",
            "    accuracy                           0.81        16\n",
            "   macro avg       0.86      0.81      0.81        16\n",
            "weighted avg       0.86      0.81      0.81        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(true_list, predict_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmPDu0m6NZ7"
      },
      "source": [
        "#Conclusao"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElNB_0zg6P1S"
      },
      "source": [
        "O modelo acerta de maneira interessante quando a imagem se trata de PNEUMONIA, logo quando é dado que é pneumonia há uma grande probabilidade de ser de fato PNEUMONIA. Porém quando é um pulmão nomal o modelo obteve apensa 0.62 de recall,logo um pulmão com pneumonia pode ser classificado como um pulmão normal\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_m9cR6v63Sb"
      },
      "source": [
        "#Funcoes uteis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxHMRG0Z3X9Z"
      },
      "outputs": [],
      "source": [
        "def imprime_torchimg(image,label):\n",
        "  image = image.permute(1, 2, 0)\n",
        "  image = np.array(image)\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.text(10, 10, f'Predicted: {label}', fontsize=12, color='white', backgroundcolor='red')\n",
        "  plt.show()\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "map = {\n",
        "    0: 'NORMAL',\n",
        "    1: 'PNEUMONIA'\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vrtD6bf0QmxE",
        "btFCm6fvT7NV",
        "NNcIvgH95ZDB",
        "XM8Ocae35pPf"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
